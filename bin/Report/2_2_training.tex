\section{Training} \label {chapter:training}

The neural network that is implemented has to be trained to the type of data it will be processing. To do this the data from targets.txt is divided into a training, validation and test set. By changing the parameters of the network and comparing error's in the validation layer, the \enquote{optimal} parameters can be found.

\subsection{Dividing the data}
The data (7854 features with 10 inputs) is divided into 7 folds of 7854/7=1122 input lines each. 5 of these folds will be used for training and the other two for the test and validation set respectively. The purpose of the test fold is to observe the error percentage when the network is untrained  and thus uses random weight between -0.5 and -0.5. The training folds are used to train the network thus updating the weights of the network. After the network is trained the network processes the validation fold. For the validation fold the error percentage and sum of squared error's is calculated. Now the results from the test set and validation set can be compared and give insight in how well the network trained itself with the given parameters. 

\subsection{Evaluating the performace}
To evaluate the performance of different neural networks, lots of different neural networks with all different parameters will follow the same procedure mentioned above. The error percentage, sum of squared errors and the parameters are then stored for each network in a single txt file. 

The following parameters were changed for each network and checked for their influence:
\begin{itemize}
\item The learning rate $\alpha$
\item The amount of hidden layers
\item The amount of neurons per hidden layer
\item The amount of epochs of training
\end{itemize}

At the end, the parameters of the neural network which scored best,will be used for processing the unknown.txt inputs. 

 \subsection{The amount of training epochs}
 Because the neural network is implemented in Java code, the training epochs run quite fast therefore lets say thousand epochs, 1 hidden layer with 100 neurons will only take about ten minutes of training although it seems that after 30-50 epochs the error rate is not really improving anymore. To be sure in deciding the best parameters for the neural network, 100 epochs were run for each individual network.
 
 \subsection{Impact of the initialization}
 The initialization where each weight gets a random value between -0.5 and 0.5 does seem to effect the performance to some extend. Networks with the same parameters can have different outcomes which is expected because where the final \enquote{solution} converges, depends on the initial weights. 